{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alt cuda corr not found\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gokul/courses/CMSC828I/depthTask/flownet/models/util.py:11: ImportWarning: failed to load custom correlation modulewhich is needed for FlowNetC\n",
      "  \"which is needed for FlowNetC\", ImportWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "from skimage.color import rgb2lab\n",
    "from skimage import io\n",
    "from glob import glob\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import torch, os, cv2\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.backends.cudnn as cudnn\n",
    "\n",
    "\n",
    "from loss import EPE\n",
    "from pytorch_ssn.RAFT.core.utils.utils import InputPadder, forward_interpolate\n",
    "from pytorch_ssn.RAFT.core.raft import RAFT\n",
    "from pytorch_ssn.model.SSN import SSN, crop_like, superpixel_flow, superpixel_seg\n",
    "from pytorch_ssn.dataset import Resize, ssn_preprocess\n",
    "from pytorch_ssn.connectivity import enforce_connectivity\n",
    "from pytorch_ssn.model.util import get_spixel_image\n",
    "import pytorch_ssn.IO as IO\n",
    "import flownet.flow_transforms as flow_transforms\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "from flownet.models.FlowNetS import flownets\n",
    "\n",
    "# get_spixel_image\n",
    "os.environ['CUDA_VISIBLE_DEVICES']='0'\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(device)\n",
    "\n",
    "\n",
    "# [SINTEL TEST]\n",
    "class Sintel(Dataset):\n",
    "    def __init__(self, root = \"./data/Sintel\", folder = 'ambush_2', shape = (128,256)):\n",
    "        \n",
    "        # self.imfiles = sorted(glob(root + f'/images/{mode}/*.jpg')); self.gtfiles = sorted(glob(root + f'/groundTruth/{mode}/*.mat'))\n",
    "        self.imfiles = sorted(glob(root + f'/clean/{folder}/*.png' ))\n",
    "        self.flofiles = sorted(glob(root +f'/flow/{folder}/*.flo') )\n",
    "        assert len(self.imfiles)-1 == len(self.flofiles), f' {len(self.imfiles), len(self.flofiles)-1}'\n",
    "        self.resize = Resize(shape)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        # load image and GT segment\n",
    "        imfile1,imfile2, flofile = self.imfiles[i],self.imfiles[i+1], self.flofiles[i]        \n",
    "        im1,im2, flo = io.imread(imfile1) , io.imread(imfile2) , IO.read(flofile)\n",
    "        # im1,im2, flo = img_as_float(io.imread(imfile1)), img_as_float(io.imread(imfile2)), IO.read(flofile)\n",
    "        im1,im2, flo = self.resize(im1, im1.shape[:2]),self.resize(im2, im2.shape[:2]), self.resize(flo, flo.shape[:2])\n",
    "\n",
    "        h,w = im1.shape[:2]\n",
    "        k = int(0.5 * (h*w)//25 )\n",
    "        ssn_inputs, ssn_args = ssn_preprocess(rgb2lab(im1), None, k )\n",
    "        im1 = np.transpose(im1, [2, 0, 1]).astype(np.float32)\n",
    "        im2 = np.transpose(im2, [2, 0, 1]).astype(np.float32)\n",
    "        flo = np.transpose(flo, [2, 0, 1]).astype(np.float32)\n",
    "        return [im1, im2], flo, ssn_inputs, ssn_args\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.flofiles)\n",
    "\n",
    "\n",
    "def imgtensor2np(img):\n",
    "    return img.permute(1,2,0).detach().cpu().numpy()\n",
    "def to_device(args, device):\n",
    "    args_out = []\n",
    "    for arg in args:\n",
    "        if isinstance(arg, list):\n",
    "            arg = [ elem.to(device) for elem in arg ]\n",
    "        else:\n",
    "            arg = arg.to(device)\n",
    "        args_out.append(arg)\n",
    "    return args_out\n",
    "\n",
    "\n",
    "def connect_segments(new_spix_indices, num_h, num_w, h, w):\n",
    "    new_spix_indices = new_spix_indices[0]\n",
    "    new_spix_indices = new_spix_indices[:, :h, :w].contiguous()\n",
    "    spix_index = new_spix_indices.cpu().numpy()[0]\n",
    "    spix_index = spix_index.astype(int)\n",
    "\n",
    "    segment_size = (h * w) / (int(num_h*num_w) * 1.0)\n",
    "    min_size = int(0.06 * segment_size)\n",
    "    max_size = int(3 * segment_size)\n",
    "    spix_index = enforce_connectivity(spix_index[np.newaxis, :, :], min_size, max_size)[0]\n",
    "    spix_index = torch.tensor(spix_index).unsqueeze(0).unsqueeze(0).to(device)\n",
    "    return spix_index\n",
    "\n",
    "def segmentfromLabels(given_img, new_spix_indices, num_h,num_w, connect=False):\n",
    "    h, w = given_img.shape[0], given_img.shape[1]\n",
    "    new_spix_indices = new_spix_indices[:, :h, :w].contiguous()\n",
    "    spix_index = new_spix_indices.cpu().numpy()[0]\n",
    "    spix_index = spix_index.astype(int)\n",
    "\n",
    "    if connect:\n",
    "        segment_size = (given_img.shape[0] * given_img.shape[1]) / (int(num_h*num_w) * 1.0)\n",
    "        min_size = int(0.06 * segment_size)\n",
    "        max_size = int(3 * segment_size)\n",
    "        spix_index = enforce_connectivity(spix_index[np.newaxis, :, :], min_size, max_size)[0]\n",
    "\n",
    "    return  get_spixel_image(given_img, spix_index)\n",
    "\n",
    "input_transform_FS = transforms.Compose([\n",
    "    transforms.Normalize(mean=[0,0,0], std=[255,255,255]),\n",
    "    transforms.Normalize(mean=[0.411,0.432,0.45], std=[1,1,1])\n",
    "])\n",
    "def flowNetS(flownet, im1, im2, transform, div_flow = 20):\n",
    "    global device    \n",
    "    image1, image2 = transform(im1[0]), transform(im2[0])\n",
    "    input_var = torch.cat([image1, image2]).unsqueeze(0).to(device)\n",
    "    flow_out = flownet(input_var)\n",
    "    flow_out = F.interpolate(flow_out, size=image1.size()[-2:], mode='bilinear', align_corners=False) * div_flow\n",
    "    return flow_out\n",
    "\n",
    "def raftFlow(im1, im2, net):\n",
    "    padder = InputPadder(im1.shape, mode='sintel')\n",
    "    input1, input2 = padder.pad(im1, im2)\n",
    "    _, flow_pr = net(input1, input2, iters=24, test_mode=True)\n",
    "    return flow_pr\n",
    "def superpixel_flow( flow, spix_indices):\n",
    "    B, _, H, W  = spix_indices.size()\n",
    "    spix_indices = spix_indices.reshape(B,1, -1)\n",
    "    flow = flow.reshape(B,2, -1)\n",
    "    \n",
    "    for b in range(flow.size(0)):\n",
    "        for Ci in range(len(torch.unique(spix_indices))):\n",
    "            Ci_ROI = spix_indices == Ci\n",
    "            flowCi_patchx, flowCi_patchy = flow[b, :1][Ci_ROI[b]], flow[b, 1:][Ci_ROI[b]] \n",
    "            meanx, meany = torch.mean(flowCi_patchx), torch.mean(flowCi_patchy)\n",
    "            flow[b, :1][Ci_ROI[b]] = meanx\n",
    "            flow[b, 1:][Ci_ROI[b]] = meany\n",
    "\n",
    "    segmentedflow = flow.reshape(B, 2, H, W)\n",
    "    return segmentedflow, spix_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> using ssn pre-trained model './pytorch_ssn/model/slic_model/45000_0.527_model.pt'\n",
      "SSN Parameter Count: 214962\n",
      "=> using flownet pre-trained model './checkpoints/flownets_EPE1.951.pth.tar'\n",
      "Flownet Parameter Count: 38675536\n"
     ]
    }
   ],
   "source": [
    "class ARGS:\n",
    "    def __init__(self):\n",
    "        self.n_spixels=100\n",
    "        self.num_steps=10\n",
    "        self.pre_dir='./pytorch_ssn/model/slic_model/45000_0.527_model.pt'        \n",
    "        self.root = 'data'\n",
    "        self.flownet_dir = \"./checkpoints/flownets_EPE1.951.pth.tar\"\n",
    "        self.raft_dir = './checkpoints/7_tartan.pth'\n",
    "        self.mixed_precision = True; self.alternate_corr=False; self.dropout = 0.0\n",
    "        self.small_ = False\n",
    "        self.savefolder =  './checkpoints/sintelsegflow'\n",
    "\n",
    "args = ARGS()\n",
    "\n",
    "\n",
    "IO.foldercheck(f'{args.savefolder}/')\n",
    "\n",
    "### raft flow network -  NA \n",
    "# net = torch.nn.DataParallel(RAFT(args))\n",
    "# net.load_state_dict(torch.load(args.raft_dir))\n",
    "# net = net.module.to(device)\n",
    "# print(\"=> using RAFT pre-trained model '{}'\".format(args.raft_dir))\n",
    "# print(\"Raft Parameter Count: %d\" % net.count_parameters())\n",
    "\n",
    "# flow_pr = raftFlow(im1, im2, net)\n",
    "# segflow_pred, _ = superpixel_flow( flow_pr.clone(), spix_indices)    \n",
    "# epe.append(EPE(flow_pr, flow).item())\n",
    "# segepe.append(EPE(segflow_pred, flow).item())\n",
    "###\n",
    "\n",
    "# ssn layer\n",
    "SSNLayer = SSN(args.pre_dir, spixel_size=(5,5),dtype = 'layer', device = device)\n",
    "print(\"=> using ssn pre-trained model '{}'\".format(args.pre_dir))\n",
    "print(\"SSN Parameter Count: %d\" % SSNLayer.module.count_parameters())\n",
    "\n",
    "# load flownet model\n",
    "network_data = torch.load(args.flownet_dir)\n",
    "print(\"=> using flownet pre-trained model '{}'\".format(args.flownet_dir))\n",
    "flownet = flownets(network_data).to(device)\n",
    "print(\"Flownet Parameter Count: %d\" % flownet.count_parameters())\n",
    "\n",
    "cudnn.benchmark = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for folder in ['ambush_2', 'alley_1']:\n",
    "    dataset = Sintel(folder=folder)\n",
    "    dataloader= DataLoader(dataset,batch_size=1, shuffle=False, num_workers=1)\n",
    "    IO.foldercheck(f'{args.savefolder}/{folder}/')\n",
    "    with torch.no_grad():\n",
    "        flownet.eval(); SSNLayer.eval()\n",
    "        epe,epeS, segepe, segepeS = [],[], [], []\n",
    "        for idx, data_sample in tqdm(enumerate(dataloader)):\n",
    "            [im1, im2], flow, ssn_input, ssn_params = data_sample\n",
    "            im1, im2, flow = to_device([im1, im2, flow], device)\n",
    "            \n",
    "            flow_S = flowNetS(flownet, im1.clone(), im2.clone(), input_transform_FS, div_flow = 20)\n",
    "            # epe.append(EPE(flow_pr, flow).item())\n",
    "\n",
    "            ssn_input = ssn_input.to(device)  \n",
    "            ssn_params = to_device(ssn_params, device)\n",
    "            ssn_params.extend([None])\n",
    "            _, spix_indices = SSNLayer(ssn_input, ssn_params)    \n",
    "\n",
    "            spix_indices = crop_like(spix_indices.unsqueeze(1), im1)\n",
    "            segflow_GT, _ = superpixel_flow( flow.clone(), spix_indices)\n",
    "            segflowS_pred,_ = superpixel_flow( flow_S.clone(), spix_indices)\n",
    "\n",
    "            epeS.append(EPE(flow_S, flow).item())\n",
    "            segepeS.append(EPE(segflowS_pred, flow).item())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            flowrgb_segGT = IO.visualize_flow( imgtensor2np(segflow_GT[0]) ) \n",
    "            flowrgb_segpredS = IO.visualize_flow(imgtensor2np(segflowS_pred[0]))\n",
    "            flowrgb_GT = IO.visualize_flow( imgtensor2np(flow[0]) ) \n",
    "            flowrgb_predS = IO.visualize_flow(imgtensor2np(flow_S[0]))\n",
    "\n",
    "            meanepeS = np.mean(epeS)\n",
    "            meansegepeS = np.mean(segepeS)    \n",
    "\n",
    "            # WE WANTED TO IMPROVE FLOWNETS's EPE SLIGHTLY USING  \n",
    "            f, plts =plt.subplots(1,4,figsize=(27, 5))\n",
    "            plts[0].imshow(flowrgb_GT)\n",
    "            plts[0].set_title('Groundtruth')\n",
    "            plts[1].axis('off')\n",
    "            plts[1].imshow(flowrgb_segpredS)\n",
    "            plts[1].set_title(f'Segmented  Flow (EPE:{meansegepeS :.2f})')\n",
    "            plts[1].axis('off')\n",
    "            plts[2].imshow(flowrgb_predS)\n",
    "            plts[2].set_title(f'Predicted Flow (EPE:{meanepeS :.2f})')\n",
    "            plts[2].axis('off')\n",
    "            plts[3].imshow(imgtensor2np(im1[0]).astype(np.uint8) )\n",
    "            plts[3].set_title('Image')\n",
    "            plts[3].axis('off')\n",
    "            f.tight_layout()\n",
    "            f.suptitle(f\" \\n FlowNetS Optical Flow\")\n",
    "\n",
    "            plt.savefig(f'{args.savefolder}/{folder}/{str(idx).zfill(5)}.png')\n",
    "#refer the savefolder for outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:00, 64.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n",
      "./checkpoints/sintelsegflow/flow_video   was not present, creating the folder...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20it [00:00, 67.05it/s]\n",
      "7it [00:00, 61.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "49it [00:00, 63.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done stitching\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for folder in ['ambush_2', 'alley_1']:\n",
    "    files=sorted(glob(f'{args.savefolder}/{folder}/*png'))\n",
    "    print(len(files))\n",
    "    for i, file in tqdm(enumerate(files)):\n",
    "        img = cv2.imread(file)\n",
    "        if(i==0):\n",
    "            IO.foldercheck(f'{args.savefolder}/flow_video')\n",
    "            h,w = img.shape[:2]    \n",
    "            writer = cv2.VideoWriter(f'{args.savefolder}/flow_video/{folder}.mp4', cv2.VideoWriter_fourcc('m', 'p', '4', 'v'), 10, (w, h))\n",
    "        # out=cv2.cvtColor(out, cv2.COLOR_RGB2BGR)\n",
    "        writer.write(img)\n",
    "    writer.release()\n",
    "print(\"Done stitching\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We infer that Enforcing Smoothness Constraint mildly helps improve the average End Poiint Error in the optical flow estimates"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.6.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
