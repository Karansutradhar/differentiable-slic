{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sceneflowdataloader.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import re\n",
    "import numpy as np\n",
    "import sys\n",
    "import chardet \n",
    "\n",
    "def readPFM(file):\n",
    "    file = open(file, 'rb')\n",
    "\n",
    "    color = None\n",
    "    width = None\n",
    "    height = None\n",
    "    scale = None\n",
    "    endian = None\n",
    "\n",
    "    header = file.readline().rstrip()\n",
    "    encode_type = chardet.detect(header)  \n",
    "    header = header.decode(encode_type['encoding'])\n",
    "    if header == 'PF':\n",
    "        color = True\n",
    "    elif header == 'Pf':\n",
    "        color = False\n",
    "    else:\n",
    "        raise Exception('Not a PFM file.')\n",
    "\n",
    "    dim_match = re.match(r'^(\\d+)\\s(\\d+)\\s$', file.readline().decode(encode_type['encoding']))\n",
    "    if dim_match:\n",
    "        width, height = map(int, dim_match.groups())\n",
    "    else:\n",
    "        raise Exception('Malformed PFM header.')\n",
    "\n",
    "    scale = float(file.readline().rstrip().decode(encode_type['encoding']))\n",
    "    if scale < 0: # little-endian\n",
    "        endian = '<'\n",
    "        scale = -scale\n",
    "    else:\n",
    "        endian = '>' # big-endian\n",
    "\n",
    "    data = np.fromfile(file, endian + 'f')\n",
    "    shape = (height, width, 3) if color else (height, width)\n",
    "\n",
    "    data = np.reshape(data, shape)\n",
    "    data = np.flipud(data)\n",
    "    return data, scale\n",
    "\n",
    "\n",
    "# from . import readpfm as rp\n",
    "def train_test_idxs(datapath):\n",
    "    folders = os.listdir(f\"{datapath}/frames_cleanpass/\")\n",
    "    disparity, segleft, imleft, imright = [], [], [], []\n",
    "    for folder in folders:\n",
    "        # disparity.extend(sorted(glob(f\"{datapath}/Monkaa/disparity/{folder}/*.pfm\")))\n",
    "        disparity.extend(sorted(glob(f\"{datapath}/object_index/{folder}/right/*.pfm\")))\n",
    "        segleft.extend(sorted(glob(f\"{datapath}/object_index/{folder}/left/*.pfm\"))) \n",
    "        imleft.extend(sorted(glob(f\"{datapath}/frames_cleanpass/{folder}/left/*.png\")))\n",
    "        imright.extend(sorted(glob(f\"{datapath}/frames_cleanpass/{folder}/right/*.png\")))\n",
    "\n",
    "    assert len(disparity) == len(imleft) == len(imright) == len(segleft), f'{len(disparity) , len(imleft) , len(imright) , len(segleft)}'\n",
    "\n",
    "    idxs = list(range(len(imleft)))\n",
    "    train_idxs, val_idxs, _, _ = train_test_split(idxs, idxs, test_size=0.2, random_state=42)\n",
    "    # return train_idxs, val_idxs\n",
    "    trainimL, valimL = np.array(imleft)[train_idxs], np.array(imleft)[val_idxs]\n",
    "    trainimR, valimR = np.array(imright)[train_idxs], np.array(imright)[val_idxs]\n",
    "    trainlabel, valabel = np.array(segleft)[train_idxs],np.array(segleft)[val_idxs]\n",
    "    traindisp, valdisp = np.array(disparity)[train_idxs], np.array(disparity)[val_idxs] \n",
    "    return trainimL, trainimR,trainlabel,traindisp, valimL,  valimR,  valabel,  valdisp\n",
    "\n",
    "class SceneFlowLoader(Dataset):\n",
    "    def __init__(self, root, mode = 'train', transform=None, target_transform=None,\n",
    "                 co_transform=None):\n",
    "        \n",
    "        if mode == 'train':\n",
    "            self.imL_path_list, self.imR_path_list,self.label_path_list,self.disp_path_list,_,_,_,_ = train_test_idxs(root)\n",
    "        if mode == 'val':\n",
    "            _,_,_,_,self.imL_path_list, self.imR_path_list,self.label_path_list,self.disp_path_list = train_test_idxs(root)\n",
    "        print(f\"Number of {mode} samples : {len(self.imL_path_list)}\")\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "        self.co_transform = co_transform\n",
    "    def __len__(self):\n",
    "        return len(self.disp_path_list)\n",
    "    def __getitem__(self, index):\n",
    "        left  = self.imL_path_list[index]\n",
    "        right = self.imR_path_list[index]\n",
    "        disp_L= self.disp_path_list[index]\n",
    "        seg_L = self.label_path_list[index]\n",
    "                \n",
    "        left_img = cv2.imread(left)\n",
    "        right_img = cv2.imread(right)\n",
    "        label, _ = readPFM(seg_L)\n",
    "        disp, scaleL = readPFM(disp_L)\n",
    "        label =  np.ascontiguousarray(label,dtype=np.float32)[..., np.newaxis]\n",
    "        \n",
    "        disp = np.ascontiguousarray(disp,dtype=np.float32)[..., np.newaxis]\n",
    "\n",
    "        assert (self.transform is not None) and (self.target_transform is not None)\n",
    "        # print(left_img.shape, right_img.shape, label.shape, disp.shape)\n",
    "        if self.co_transform is not None:\n",
    "            inputs, label, disp = self.co_transform([left_img, right_img], label, disp)\n",
    "\n",
    "        if self.transform is not None:\n",
    "            imL = self.transform(inputs[0])\n",
    "            imR = self.transform(inputs[1])\n",
    "\n",
    "        if self.target_transform is not None:\n",
    "            label = self.target_transform(label)\n",
    "            disp = self.target_transform(disp)\n",
    "\n",
    "        return imL, imR, label, disp\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total classes 47.\n",
      "Number of train samples : 6931\n",
      "Total classes 47.\n",
      "Number of val samples : 1733\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import torchvision.transforms as transforms\n",
    "from dataset.sceneflowdataloader import SceneFlowLoader\n",
    "import torch\n",
    "\n",
    "from glob import glob\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import argparse\n",
    "import shutil\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim\n",
    "import torch.utils.data\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.utils import make_grid\n",
    "\n",
    "import superpixelnet.flow_transforms as flow_transforms\n",
    "from superpixelnet.models.Spixel_single_layer import SpixelNet1l_bn\n",
    "from superpixelnet.loss import compute_semantic_pos_loss\n",
    "import datetime\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "from superpixelnet.train_util import *\n",
    "\n",
    "# psmnet\n",
    "from  models import *\n",
    "from models.submodule import disparityregression\n",
    "\n",
    "\n",
    "best_EPE = -1\n",
    "n_iter = 0\n",
    "\n",
    "def imgtensor2np(img):\n",
    "    return img.permute(1,2,0).detach().cpu().numpy()\n",
    "def to_device(args, device):\n",
    "    args_out = []\n",
    "    for arg in args:\n",
    "        if isinstance(arg, list):\n",
    "            arg = [ elem.to(device) for elem in arg ]\n",
    "        else:\n",
    "            arg = arg.to(device)\n",
    "        args_out.append(arg)\n",
    "    return args_out\n",
    "\n",
    "class ARG:\n",
    "    def __init__(self):\n",
    "        self.dataset = 'SceneFlow'\n",
    "        self.arch = 'SpixelNet1l_bn'\n",
    "        # self.data= './data_preprocessing/Data'; self.data= './NYU'\n",
    "        self.data = \"./dataset/Monkaa\"\n",
    "        self.savepath = './checkpoints'\n",
    "        # self.train_img_height = 256; self.train_img_width= 512 \n",
    "        self.train_img_height = 128; self.train_img_width= 256\n",
    "        self.input_img_height = 208;self.input_img_width = 208 \n",
    "        \n",
    "        self.workers = 4; self.epochs = 300  *10000\n",
    "        self.start_epoch = 0; self.epoch_size = 6000; self.batch_size = 1;\n",
    "        self.solver = 'adam'; self.lr= 0.00005; \n",
    "        self.momentum = 0.9; self.beta = 0.999; self.weight_decay=4e-4;self.bias_decay=0\n",
    "        self.milestones=[200000]; self.additional_step=100000; \n",
    "        self.pos_weight = 0.003; self.downsize = 16;\n",
    "        self.gpu = '0'; self.print_freq = 10; self.record_freq  = 5; self.label_factor=5; self.pretrained = None;\n",
    "        self.no_date=True\n",
    "        \n",
    "        self.maxdisp = 192; self.psmmodel = 'basic'\n",
    "        self.seed = 1; self.pretrainedpsmnet = None\n",
    "\n",
    "args = ARG()\n",
    "\n",
    "# !----- NOTE the current code does not support cpu training -----!\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = args.gpu\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    print('Current code does not support CPU training! Sorry about that.')\n",
    "    exit(1)\n",
    "\n",
    "# def main():\n",
    "#     global args, best_EPE, save_path, intrinsic\n",
    "\n",
    "# ============= savor setting ===================\n",
    "save_path = '{}_{}_{}epochs{}_b{}_lr{}_posW{}'.format(\n",
    "    args.arch,\n",
    "    args.solver,\n",
    "    args.epochs,\n",
    "    '_epochSize'+str(args.epoch_size) if args.epoch_size > 0 else '',\n",
    "    args.batch_size,\n",
    "    args.lr,\n",
    "    args.pos_weight,\n",
    ")\n",
    "if not args.no_date:\n",
    "    timestamp = datetime.datetime.now().strftime(\"%y_%m_%d_%H_%M\")\n",
    "else:\n",
    "    timestamp = ''\n",
    "save_path = os.path.abspath(args.savepath) + '/' + os.path.join(args.dataset, save_path  +  '_' + timestamp )\n",
    "\n",
    "# ==========  Data loading code ==============\n",
    "input_transform = transforms.Compose([\n",
    "    flow_transforms.ArrayToTensor(),\n",
    "    transforms.Normalize(mean=[0,0,0], std=[255,255,255]),\n",
    "    transforms.Normalize(mean=[0.411,0.432,0.45], std=[1,1,1])\n",
    "])\n",
    "\n",
    "val_input_transform = transforms.Compose([\n",
    "    flow_transforms.ArrayToTensor(),\n",
    "    transforms.Normalize(mean=[0, 0, 0], std=[255, 255, 255]),\n",
    "    transforms.Normalize(mean=[0.411, 0.432, 0.45], std=[1, 1, 1])\n",
    "])\n",
    "\n",
    "target_transform = transforms.Compose([\n",
    "    flow_transforms.ArrayToTensor(),\n",
    "])\n",
    "\n",
    "co_transform = flow_transforms.Compose([\n",
    "        flow_transforms.RandomCrop((args.train_img_height ,args.train_img_width))\n",
    "    ])\n",
    "\n",
    "N_CLASSES = 50\n",
    "trainset = SceneFlowLoader(args.data, mode='train', transform=input_transform, target_transform=target_transform, co_transform=co_transform)\n",
    "valset = SceneFlowLoader(args.data, mode='val', transform=val_input_transform, target_transform=target_transform, co_transform=co_transform)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    trainset, batch_size=args.batch_size,\n",
    "    num_workers=args.workers, pin_memory=True, shuffle=True, drop_last=True)\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    valset, batch_size=args.batch_size,\n",
    "    num_workers=args.workers, pin_memory=True, shuffle=False, drop_last=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> creating model 'SpixelNet1l_bn'\n",
      "Number of PSM model parameters: 3287360\n",
      "=> setting adam solver\n",
      "=> will save everything to /home/gokul/courses/CMSC828I/dispTask/checkpoints/SceneFlow/SpixelNet1l_bn_adam_3000000epochs_epochSize6000_b1_lr5e-05_posW0.003_\n"
     ]
    }
   ],
   "source": [
    "# import models.stackhourglass.PSMNet as stackhourglass\n",
    "torch.manual_seed(args.seed)\n",
    "if device.type  == 'cuda':\n",
    "    torch.cuda.manual_seed(args.seed)\n",
    "\n",
    "\n",
    "# ============== create model ====================\n",
    "if args.pretrained:\n",
    "    network_data = torch.load(args.pretrained)\n",
    "    args.arch = network_data['arch']\n",
    "    print(\"=> using pre-trained model '{}'\".format(args.arch))\n",
    "else:\n",
    "    network_data = None\n",
    "    print(\"=> creating model '{}'\".format(args.arch))\n",
    "\n",
    "model = SpixelNet1l_bn( data = network_data).cuda()\n",
    "model = torch.nn.DataParallel(model).cuda()\n",
    "\n",
    "if args.psmmodel == 'stackhourglass':\n",
    "    psmnet = stackhourglass(args.maxdisp, slicmode=False)\n",
    "elif args.psmmodel == 'basic':\n",
    "    psmnet = basic(args.maxdisp)\n",
    "else:\n",
    "    print('no model')\n",
    "psmnet = torch.nn.DataParallel(psmnet)\n",
    "psmnet.to(device)\n",
    "\n",
    "if args.pretrainedpsmnet is not None:\n",
    "    print('Load pretrained model')\n",
    "    pretrain_dict = torch.load(args.pretrainedpsmnet)\n",
    "    psmnet.load_state_dict(pretrain_dict['state_dict'])\n",
    "\n",
    "print('Number of PSM model parameters: {}'.format(sum([p.data.nelement() for p in psmnet.parameters()])))\n",
    "\n",
    "\n",
    "cudnn.benchmark = True\n",
    "\n",
    "#=========== creat optimizer, we use adam by default ==================\n",
    "assert(args.solver in ['adam', 'sgd'])\n",
    "print('=> setting {} solver'.format(args.solver))\n",
    "\n",
    "param_groups = [{'params': model.module.bias_parameters(), 'weight_decay': args.bias_decay},\n",
    "                {'params': model.module.weight_parameters(), 'weight_decay': args.weight_decay},\n",
    "                ]\n",
    "param_groups.extend([{'params': psmnet.module.bias_parameters(), 'weight_decay': args.weight_decay},\n",
    "                    {'params': psmnet.module.weight_parameters(), 'weight_decay': args.weight_decay}\n",
    "                    ])\n",
    "if args.solver == 'adam':\n",
    "    optimizer = torch.optim.Adam(param_groups, args.lr,\n",
    "                                    betas=(args.momentum, args.beta))\n",
    "elif args.solver == 'sgd':\n",
    "    optimizer = torch.optim.SGD(param_groups, args.lr,\n",
    "                                momentum=args.momentum)\n",
    "\n",
    "# for continues training\n",
    "if args.pretrained and ('dataset' in network_data):\n",
    "    if args.pretrained and args.dataset == network_data['dataset'] :\n",
    "        optimizer.load_state_dict(network_data['optimizer'])\n",
    "        best_EPE = network_data['best_EPE']\n",
    "        args.start_epoch = network_data['epoch']\n",
    "        save_path = os.path.dirname(args.pretrained)\n",
    "\n",
    "\n",
    "\n",
    "print('=> will save everything to {}'.format(save_path))\n",
    "if not os.path.exists(save_path):\n",
    "    os.makedirs(save_path)\n",
    "\n",
    "train_writer = SummaryWriter(os.path.join(save_path, 'train'))\n",
    "val_writer = SummaryWriter(os.path.join(save_path, 'val'))\n",
    "\n",
    "# spixelID: superpixel ID for visualization,\n",
    "# XY_feat: the coordinate feature for position loss term\n",
    "spixelID, XY_feat_stack = init_spixel_grid(args)\n",
    "val_spixelID,  val_XY_feat_stack = init_spixel_grid(args, b_train=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeOutput(cost, Ql, S):\n",
    "    upsampled_cost = upfeat(cost, Ql, S, S)\n",
    "    assert upsampled_cost.size()[2] == Ql.size()[2]\n",
    "    assert upsampled_cost.size()[3] == Ql.size()[3]\n",
    "    upsampled_cost = F.upsample(upsampled_cost.unsqueeze(1), [args.maxdisp,Ql.size()[2],Ql.size()[3]], mode='trilinear').squeeze(1)\n",
    "    output = F.softmax(upsampled_cost)\n",
    "    output = disparityregression(args.maxdisp)(output)\n",
    "    return output\n",
    "\n",
    "def train(train_loader, model, optimizer, epoch, train_writer, init_spixl_map_idx, XY_feat_stack):\n",
    "    global n_iter, args, intrinsic\n",
    "\n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "\n",
    "    total_loss = AverageMeter()\n",
    "    losses_slic = AverageMeter()\n",
    "    losses_psm = AverageMeter()\n",
    "\n",
    "    epoch_size =  len(train_loader) if args.epoch_size == 0 else min(len(train_loader), args.epoch_size)\n",
    "\n",
    "    # switch to train mode\n",
    "    model.train()\n",
    "    psmnet.train()\n",
    "    end = time.time()\n",
    "    iteration = 0\n",
    "\n",
    "    for i, sample in enumerate(train_loader):\n",
    "        imL, imR, label, labelR, disp_true = to_device(sample, device)\n",
    "        iteration = i + epoch * epoch_size\n",
    "\n",
    "        # ========== adjust lr if necessary  ===============\n",
    "        if (iteration + 1) in args.milestones:\n",
    "            state_dict = optimizer.state_dict()\n",
    "            for param_group in state_dict['param_groups']:\n",
    "                param_group['lr'] = args.lr * ((0.5) ** (args.milestones.index(iteration + 1) + 1))\n",
    "            optimizer.load_state_dict(state_dict)\n",
    "\n",
    "        # ========== complete data loading ================\n",
    "        label_1hot = label2one_hot_torch(label, C=N_CLASSES) # set C=50 as SSN does\n",
    "        LABXY_feat_tensor = build_LABXY_feat(label_1hot, XY_feat_stack)  # B* (50+2 )* H * W\n",
    "        label_1hotR = label2one_hot_torch(labelR, C=N_CLASSES) # set C=50 as SSN does\n",
    "        LABXY_feat_tensorR = build_LABXY_feat(label_1hotR, XY_feat_stack)  # B* (50+2 )* H * W\n",
    "\n",
    "        torch.cuda.synchronize()\n",
    "        data_time.update(time.time() - end)\n",
    "\n",
    "\n",
    "        # ========== predict association map ============\n",
    "        Ql = model(imL)\n",
    "        Qr = model(imR)\n",
    "        # ========== compute slic loss ============\n",
    "        slic_lossL, loss_sem, loss_pos = compute_semantic_pos_loss( Ql, LABXY_feat_tensor,\n",
    "                                                                pos_weight= args.pos_weight, kernel_size=args.downsize)\n",
    "        slic_lossR, _, _ = compute_semantic_pos_loss( Qr, LABXY_feat_tensorR,\n",
    "                                                                pos_weight= args.pos_weight, kernel_size=args.downsize)\n",
    "        \n",
    "        slic_loss = 0.5* (slic_lossL + slic_lossR)\n",
    "\n",
    "        # ========== compute disparity map ============\n",
    "        mask = disp_true < args.maxdisp\n",
    "        mask.detach_()\n",
    "        #----\n",
    "        S = 4; m = 0.003\n",
    "        pooled_imL = poolfeat(imL, Ql.clone(), S, S)\n",
    "        pooled_imR = poolfeat(imR, Qr.clone(), S, S)\n",
    "\n",
    "        if args.psmmodel == 'stackhourglass':\n",
    "            cost1, cost2, cost3 = psmnet(pooled_imL, pooled_imR)\n",
    "            # output1 = torch.squeeze(output1,1); output2 = torch.squeeze(output2,1); output3 = torch.squeeze(output3,1)\n",
    "            # psmloss = 0.5*F.smooth_l1_loss(output1[mask], disp_true[mask], size_average=True) + \\\n",
    "            #     0.7*F.smooth_l1_loss(output2[mask], disp_true[mask], size_average=True) + \\\n",
    "            #         F.smooth_l1_loss(output3[mask], disp_true[mask], size_average=True) \n",
    "        elif args.psmmodel == 'basic':\n",
    "            cost = psmnet(pooled_imL,pooled_imR)\n",
    "            output  = computeOutput(cost, Ql, S)\n",
    "            # output = torch.squeeze(output,1)\n",
    "            psmloss = F.smooth_l1_loss(output[mask], disp_true[mask], size_average=True)\n",
    "\n",
    "        loss = psmloss + slic_loss\n",
    "\n",
    "        # ========= back propagate ===============\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # ========  measure batch time ===========\n",
    "        torch.cuda.synchronize()\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "        # =========== record and display the loss ===========\n",
    "        # record loss and EPE\n",
    "        total_loss.update(loss.item(), imL.size(0))\n",
    "        losses_slic.update(slic_loss.item(), imL.size(0))\n",
    "        losses_psm.update(psmloss.item(), imL.size(0))\n",
    "\n",
    "\n",
    "\n",
    "        if i % args.print_freq == 0:\n",
    "            print('train Epoch: [{0}][{1}/{2}]\\t Time {3}\\t Data {4}\\t Total_loss {5}\\t Loss_sem {6}\\t Loss_pos {7}\\t'\n",
    "                    .format(epoch, i, epoch_size, batch_time, data_time, total_loss, losses_slic, losses_psm))\n",
    "\n",
    "            train_writer.add_scalar('Train_loss', slic_loss.item(), i + epoch*epoch_size)\n",
    "            train_writer.add_scalar('learning rate',optimizer.param_groups[0]['lr'], i + epoch * epoch_size)\n",
    "\n",
    "        n_iter += 1\n",
    "        if i >= epoch_size:\n",
    "            break\n",
    "\n",
    "        if (iteration) >= (args.milestones[-1] + args.additional_step):\n",
    "            break\n",
    "        \n",
    "        # =========== write information to tensorboard ===========\n",
    "        if epoch % args.record_freq == 0:\n",
    "            train_writer.add_scalar('Train_loss_epoch', slic_loss.item(),  epoch )\n",
    "            train_writer.add_scalar('loss_sem',  loss_sem.item(),  epoch )\n",
    "            train_writer.add_scalar('loss_pos',  loss_pos.item(), epoch)\n",
    "\n",
    "            #save image\n",
    "            mean_values = torch.tensor([0.411, 0.432, 0.45], dtype=imL.dtype).view(3, 1, 1)\n",
    "            input_l_save = (make_grid((input + mean_values).clamp(0, 1), nrow=args.batch_size))\n",
    "            label_save = make_grid(args.label_factor * label)\n",
    "\n",
    "            train_writer.add_image('Input', input_l_save, epoch)\n",
    "            train_writer.add_image('label', label_save, epoch)\n",
    "\n",
    "            # init_spixl_map_idx = spixelID\n",
    "            curr_spixl_map = update_spixl_map(init_spixl_map_idx,Ql)\n",
    "            spixel_lab_save = make_grid(curr_spixl_map, nrow=args.batch_size)[0, :, :]\n",
    "            spixel_viz, _ = get_spixel_image(input_l_save, spixel_lab_save)\n",
    "            train_writer.add_image('Spixel viz', spixel_viz, epoch)\n",
    "\n",
    "            # save associ map,  --- for debug only\n",
    "            _, prob_idx = torch.max(Ql, dim=1, keepdim=True)\n",
    "            prob_map_save = make_grid(assign2uint8(prob_idx))\n",
    "            train_writer.add_image('assigment idx', prob_map_save, epoch)\n",
    "\n",
    "            train_writer.add_image('disp map', imgtensor2np(output[0]) , epoch, dataformats='HWC')\n",
    "            train_writer.add_image('disp map GT', imgtensor2np(disp_true[0]) , epoch,dataformats='HWC')\n",
    "            print('==> write train step %dth to tensorboard' % i)\n",
    "\n",
    "        return total_loss.avg, losses_psm.avg, iteration\n",
    "\n",
    "def validate(val_loader, networks, epoch, val_writer, init_spixl_map_idx, XY_feat_stack):\n",
    "    global n_iter,   args,    intrinsic\n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "\n",
    "    total_loss = AverageMeter()\n",
    "    losses_psm = AverageMeter()\n",
    "    losses_slic = AverageMeter()\n",
    "\n",
    "    # set the validation epoch-size, we only randomly val. 400 batches during training to save time\n",
    "    epoch_size = min(len(val_loader), 400)\n",
    "\n",
    "    model, psmnet = networks\n",
    "    # switch to eval mode\n",
    "    model.eval()\n",
    "    psmnet.eval()\n",
    "    end = time.time()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, sample in enumerate(val_loader):\n",
    "            imL, imR, label, labelR, disp_true = to_device(sample, device)\n",
    "\n",
    "\n",
    "            # ========== complete data loading ================\n",
    "            label_1hot = label2one_hot_torch(label, C=N_CLASSES) # set C=50 as SSN does\n",
    "            LABXY_feat_tensor = build_LABXY_feat(label_1hot, XY_feat_stack)  # B* (50+2 )* H * W\n",
    "            label_1hotR = label2one_hot_torch(labelR, C=N_CLASSES) # set C=50 as SSN does\n",
    "            LABXY_feat_tensorR = build_LABXY_feat(label_1hotR, XY_feat_stack)  # B* (50+2 )* H * W\n",
    "\n",
    "            torch.cuda.synchronize()\n",
    "            data_time.update(time.time() - end)\n",
    "\n",
    "\n",
    "            # ========== predict association map ============\n",
    "            Ql = model(imL)\n",
    "            Qr = model(imR)\n",
    "            # ========== compute slic loss ============\n",
    "            slic_lossL, loss_sem, loss_pos = compute_semantic_pos_loss( Ql, LABXY_feat_tensor,\n",
    "                                                                    pos_weight= args.pos_weight, kernel_size=args.downsize)\n",
    "            slic_lossR, _, _ = compute_semantic_pos_loss( Qr, LABXY_feat_tensorR,\n",
    "                                                                    pos_weight= args.pos_weight, kernel_size=args.downsize)\n",
    "            \n",
    "            slic_loss = 0.5* (slic_lossL + slic_lossR)\n",
    "\n",
    "            # ========== compute disparity map ============\n",
    "            mask = disp_true < args.maxdisp\n",
    "            mask.detach_()\n",
    "            #----\n",
    "            S = 4; m = 0.003\n",
    "            pooled_imL = poolfeat(imL, Ql.clone(), S, S)\n",
    "            pooled_imR = poolfeat(imR, Qr.clone(), S, S)\n",
    "\n",
    "            cost = psmnet(pooled_imL,pooled_imR)\n",
    "            output  = computeOutput(cost, Ql, S)\n",
    "            # output = torch.squeeze(output,1)\n",
    "            psmloss = F.smooth_l1_loss(output[mask], disp_true[mask], size_average=True)\n",
    "\n",
    "            loss = psmloss + slic_loss\n",
    "\n",
    "            # measure elapsed time\n",
    "            torch.cuda.synchronize()\n",
    "            batch_time.update(time.time() - end)\n",
    "            end = time.time()\n",
    "\n",
    "            # record loss and EPE\n",
    "            total_loss.update(loss.item(), imL.size(0))\n",
    "            losses_psm.update(psmloss.item(), imL.size(0))\n",
    "            losses_slic.update(slic_loss.item(), imL.size(0))\n",
    "\n",
    "            if i % args.print_freq == 0:\n",
    "                print('val Epoch: [{0}][{1}/{2}]\\t Time {3}\\t Data {4}\\t Total_loss {5}\\t Loss_sem {6}\\t Loss_pos {7}\\t'\n",
    "                    .format(epoch, i, epoch_size, batch_time, data_time, total_loss, losses_psm, losses_slic))\n",
    "\n",
    "            if i >= epoch_size:\n",
    "                break\n",
    "\n",
    "    # =============  write result to tensorboard ======================\n",
    "    if epoch % args.record_freq == 0:\n",
    "        val_writer.add_scalar('val_loss_epoch', loss.item(), epoch)\n",
    "        val_writer.add_scalar('val_loss_sem', psmloss.item(), epoch)\n",
    "        val_writer.add_scalar('val_loss_slic', slic_loss.item(), epoch)\n",
    "\n",
    "        mean_values = torch.tensor([0.411, 0.432, 0.45], dtype=imL.dtype).view(3, 1, 1)\n",
    "        input_l_save = (make_grid((input + mean_values).clamp(0, 1), nrow=args.batch_size))\n",
    "\n",
    "\n",
    "        curr_spixl_map = update_spixl_map(init_spixl_map_idx, output)\n",
    "        spixel_lab_save = make_grid(curr_spixl_map, nrow=args.batch_size)[0, :, :]\n",
    "        spixel_viz, _ = get_spixel_image(input_l_save, spixel_lab_save)\n",
    "\n",
    "        label_save = make_grid(args.label_factor * label)\n",
    "\n",
    "        val_writer.add_image('Input', input_l_save, epoch)\n",
    "        val_writer.add_image('label', label_save, epoch)\n",
    "        val_writer.add_image('Spixel viz', spixel_viz, epoch)\n",
    "\n",
    "        val_writer.add_image('disp map', imgtensor2np(output[0]) , epoch, dataformats='HWC')\n",
    "        val_writer.add_image('disp map GT', imgtensor2np(disp_true[0]) , epoch,dataformats='HWC')\n",
    "\n",
    "        # --- for debug\n",
    "        #     _, prob_idx = torch.max(assign, dim=1, keepdim=True)\n",
    "        #     prob_map_save = make_grid(assign2uint8(prob_idx))\n",
    "        #     val_writer.add_image('assigment idx level %d' % j, prob_map_save, epoch)\n",
    "\n",
    "        print('==> write val step %dth to tensorboard' % i)\n",
    "\n",
    "    return total_loss.avg, losses_psm.avg\n",
    "\n",
    "\n",
    "def save_checkpoint(state, is_best, filename='checkpoint.tar'):\n",
    "    torch.save(state, os.path.join(save_path,filename))\n",
    "    if is_best:\n",
    "        shutil.copyfile(os.path.join(save_path,filename), os.path.join(save_path,'model_best.tar'))\n",
    "\n",
    "\n",
    "#===================================================================================\n",
    "#=============================== Train routine =====================================\n",
    "#===================================================================================\n",
    "\n",
    "for epoch in range(args.start_epoch, args.epochs): # epochs chosen to be 3e6 because we want to end training based on iterations - 300k\n",
    "    # train for one epoch\n",
    "    train_avg_slic, train_avg_sem, iteration = train(train_loader, model, optimizer, epoch,\n",
    "                                                        train_writer, spixelID, XY_feat_stack )\n",
    "    if epoch % args.record_freq == 0:\n",
    "        train_writer.add_scalar('Mean avg_slic', train_avg_slic, epoch)\n",
    "\n",
    "    # evaluate on validation set and save the module( and choose the best)\n",
    "    with torch.no_grad():\n",
    "        avg_slic, avg_sem  = validate(val_loader, model, epoch, val_writer, val_spixelID, val_XY_feat_stack)\n",
    "        if epoch % args.record_freq == 0:\n",
    "            val_writer.add_scalar('Mean avg_slic', avg_slic, epoch)\n",
    "\n",
    "    rec_dict = {\n",
    "            'epoch': epoch + 1,\n",
    "            'arch': args.arch,\n",
    "            'state_dict': model.module.state_dict(),\n",
    "            'best_EPE': best_EPE,\n",
    "            'optimizer': optimizer.state_dict(),\n",
    "            'dataset': args.dataset\n",
    "        }\n",
    "\n",
    "    if (iteration) >= (args.milestones[-1] + args.additional_step):\n",
    "        save_checkpoint(rec_dict, is_best =False, filename='%d_step.tar' % iteration)\n",
    "        print(\"Train finished!\")\n",
    "        break\n",
    "\n",
    "    if best_EPE < 0:\n",
    "        best_EPE = avg_sem\n",
    "    is_best = avg_sem < best_EPE\n",
    "    best_EPE = min(avg_sem, best_EPE)\n",
    "    save_checkpoint(rec_dict, is_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 128, 256])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gokul/.local/lib/python3.6/site-packages/torch/nn/functional.py:3487: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
      "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n",
      "/home/gokul/.local/lib/python3.6/site-packages/torch/nn/functional.py:3613: UserWarning: Default upsampling behavior when mode=trilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
      "  \"See the documentation of nn.Upsample for details.\".format(mode)\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 192, 128, 256])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "upsampled_cost.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 192, 1, 1])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 1, 192, 128, 256]), torch.Size([1, 48, 128, 256]))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gokul/.local/lib/python3.6/site-packages/ipykernel_launcher.py:4: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 128, 256])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PSM NET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total classes 47.\n",
      "Number of train samples : 6931\n",
      "Total classes 47.\n",
      "Number of val samples : 1733\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import torchvision.transforms as transforms\n",
    "from dataset.sceneflowdataloader import SceneFlowLoader\n",
    "import torch\n",
    "\n",
    "from glob import glob\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import argparse\n",
    "import shutil\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim\n",
    "import torch.utils.data\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.utils import make_grid\n",
    "\n",
    "import superpixelnet.flow_transforms as flow_transforms\n",
    "from superpixelnet.models.Spixel_single_layer import SpixelNet1l_bn\n",
    "from superpixelnet.loss import compute_semantic_pos_loss\n",
    "import datetime\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "from superpixelnet.train_util import poolfeat, upfeat, update_spixl_map\n",
    "\n",
    "best_EPE = -1\n",
    "n_iter = 0\n",
    "\n",
    "def imgtensor2np(img):\n",
    "    return img.permute(1,2,0).detach().cpu().numpy()\n",
    "def to_device(args, device):\n",
    "    args_out = []\n",
    "    for arg in args:\n",
    "        if isinstance(arg, list):\n",
    "            arg = [ elem.to(device) for elem in arg ]\n",
    "        else:\n",
    "            arg = arg.to(device)\n",
    "        args_out.append(arg)\n",
    "    return args_out\n",
    "\n",
    "class ARG:\n",
    "    def __init__(self):\n",
    "        self.dataset = 'SceneFlow'\n",
    "        self.arch = 'SpixelNet1l_bn'\n",
    "        # self.data= './data_preprocessing/Data'; self.data= './NYU'\n",
    "        self.data = \"./dataset/Monkaa\"\n",
    "        self.savepath = './checkpoints'\n",
    "        self.train_img_height = 256; self.train_img_width= 512 \n",
    "        # self.train_img_height = 64; self.train_img_width= 128\n",
    "        self.input_img_height = 208;self.input_img_width = 208 \n",
    "        \n",
    "        self.workers = 4; self.epochs = 300  *10000\n",
    "        self.start_epoch = 0; self.epoch_size = 6000; self.batch_size = 1;\n",
    "        self.solver = 'adam'; self.lr= 0.00005; \n",
    "        self.momentum = 0.9; self.beta = 0.999; self.weight_decay=4e-4;self.bias_decay=0\n",
    "        self.milestones=[200000]; self.additional_step=100000; \n",
    "        self.pos_weight = 0.003; self.downsize = 16;\n",
    "        self.gpu = '0'; self.print_freq = 10; self.record_freq  = 5; self.label_factor=5; self.pretrained = None;\n",
    "        self.no_date=True\n",
    "        \n",
    "        self.maxdisp = 192; self.psmmodel = 'basic'\n",
    "        self.seed = 1; self.pretrainedpsmnet = None\n",
    "\n",
    "args = ARG()\n",
    "\n",
    "# !----- NOTE the current code does not support cpu training -----!\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = args.gpu\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    print('Current code does not support CPU training! Sorry about that.')\n",
    "    exit(1)\n",
    "\n",
    "# def main():\n",
    "#     global args, best_EPE, save_path, intrinsic\n",
    "\n",
    "# ============= savor setting ===================\n",
    "save_path = '{}_{}_{}epochs{}_b{}_lr{}_posW{}'.format(\n",
    "    args.arch,\n",
    "    args.solver,\n",
    "    args.epochs,\n",
    "    '_epochSize'+str(args.epoch_size) if args.epoch_size > 0 else '',\n",
    "    args.batch_size,\n",
    "    args.lr,\n",
    "    args.pos_weight,\n",
    ")\n",
    "if not args.no_date:\n",
    "    timestamp = datetime.datetime.now().strftime(\"%y_%m_%d_%H_%M\")\n",
    "else:\n",
    "    timestamp = ''\n",
    "save_path = os.path.abspath(args.savepath) + '/' + os.path.join(args.dataset, save_path  +  '_' + timestamp )\n",
    "\n",
    "# ==========  Data loading code ==============\n",
    "input_transform = transforms.Compose([\n",
    "    flow_transforms.ArrayToTensor(),\n",
    "    transforms.Normalize(mean=[0,0,0], std=[255,255,255]),\n",
    "    transforms.Normalize(mean=[0.411,0.432,0.45], std=[1,1,1])\n",
    "])\n",
    "\n",
    "val_input_transform = transforms.Compose([\n",
    "    flow_transforms.ArrayToTensor(),\n",
    "    transforms.Normalize(mean=[0, 0, 0], std=[255, 255, 255]),\n",
    "    transforms.Normalize(mean=[0.411, 0.432, 0.45], std=[1, 1, 1])\n",
    "])\n",
    "\n",
    "target_transform = transforms.Compose([\n",
    "    flow_transforms.ArrayToTensor(),\n",
    "])\n",
    "\n",
    "co_transform = flow_transforms.Compose([\n",
    "        flow_transforms.RandomCrop((args.train_img_height ,args.train_img_width))\n",
    "    ])\n",
    "\n",
    "N_CLASSES = 50\n",
    "trainset = SceneFlowLoader(args.data, mode='train', transform=input_transform, target_transform=target_transform, co_transform=co_transform)\n",
    "valset = SceneFlowLoader(args.data, mode='val', transform=val_input_transform, target_transform=target_transform, co_transform=co_transform)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    trainset, batch_size=args.batch_size,\n",
    "    num_workers=args.workers, pin_memory=True, shuffle=True, drop_last=True)\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    valset, batch_size=args.batch_size,\n",
    "    num_workers=args.workers, pin_memory=True, shuffle=False, drop_last=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of model parameters: 5224768\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, sample in enumerate(train_loader):\n",
    "    imL, imR, label, labelR, disp_true = to_device(sample, device)\n",
    "    break    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature extractor oskip: torch.Size([1, 128, 64, 128])\n",
      "feature extractor obranch1: torch.Size([1, 32, 64, 128])\n",
      "feature extractor obranch2: torch.Size([1, 32, 64, 128])\n",
      "feature extractor obranch3: torch.Size([1, 32, 64, 128])\n",
      "feature extractor obranch4: torch.Size([1, 32, 64, 128])\n",
      "feature extractor output_feature: torch.Size([1, 320, 64, 128])\n",
      "feature extractor oskip: torch.Size([1, 128, 64, 128])\n",
      "feature extractor obranch1: torch.Size([1, 32, 64, 128])\n",
      "feature extractor obranch2: torch.Size([1, 32, 64, 128])\n",
      "feature extractor obranch3: torch.Size([1, 32, 64, 128])\n",
      "feature extractor obranch4: torch.Size([1, 32, 64, 128])\n",
      "feature extractor output_feature: torch.Size([1, 320, 64, 128])\n",
      "feature shape , torch.Size([1, 32, 64, 128])\n",
      "cost shape , torch.Size([1, 64, 48, 64, 128])\n",
      "cost0 shape , torch.Size([1, 32, 48, 64, 128])\n",
      "out1 shape , torch.Size([1, 32, 48, 64, 128])\n",
      "out2 shape , torch.Size([1, 32, 48, 64, 128])\n",
      "out3 shape , torch.Size([1, 32, 48, 64, 128])\n",
      "cost shapes 1, 2, 3:  torch.Size([1, 1, 48, 64, 128]) torch.Size([1, 1, 48, 64, 128]) torch.Size([1, 1, 48, 64, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gokul/.local/lib/python3.6/site-packages/torch/nn/functional.py:3487: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
      "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n",
      "/home/gokul/.local/lib/python3.6/site-packages/torch/nn/functional.py:3613: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
      "  \"See the documentation of nn.Upsample for details.\".format(mode)\n",
      "/home/gokul/.local/lib/python3.6/site-packages/torch/nn/functional.py:3613: UserWarning: Default upsampling behavior when mode=trilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
      "  \"See the documentation of nn.Upsample for details.\".format(mode)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred shapes 1, 2, 3:  torch.Size([1, 1, 256, 512]) torch.Size([1, 1, 256, 512]) torch.Size([1, 192, 256, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gokul/.local/lib/python3.6/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "    # return loss.data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 64, 128])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0, device='cuda:0')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(torch.isnan(disp_true))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([], device='cuda:0', grad_fn=<IndexBackward>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([], device='cuda:0', dtype=torch.bool),\n",
       " tensor([], device='cuda:0', dtype=torch.bool))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.isnan(output[mask]), torch.isnan(disp_true[mask])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 64, 128])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 64, 128])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.6.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
