{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torchvision.transforms as transforms\n",
    "from dataset.sceneflowdataloader import SceneFlowLoader\n",
    "import torch\n",
    "\n",
    "from glob import glob\n",
    "from torch.utils.data import Dataset\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch.nn.parallel\n",
    "import torch.utils.data\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.utils import make_grid\n",
    "\n",
    "import superpixelnet.flow_transforms as flow_transforms\n",
    "from superpixelnet.models.Spixel_single_layer import SpixelNet1l_bn\n",
    "from superpixelnet.loss import compute_semantic_pos_loss\n",
    "import datetime\n",
    "\n",
    "from superpixelnet.train_util import *\n",
    "\n",
    "# psmnet\n",
    "from  models import *\n",
    "from models.submodule import disparityregression\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from PIL import Image\n",
    "from matplotlib.backends.backend_agg import FigureCanvasAgg\n",
    "from matplotlib.figure import Figure\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imgtensor2np(img):\n",
    "    return img.permute(1,2,0).detach().cpu().numpy()\n",
    "def to_device(args, device):\n",
    "    args_out = []\n",
    "    for arg in args:\n",
    "        if isinstance(arg, list):\n",
    "            arg = [ elem.to(device) for elem in arg ]\n",
    "        else:\n",
    "            arg = arg.to(device)\n",
    "        args_out.append(arg)\n",
    "    return args_out\n",
    "\n",
    "class ARG:\n",
    "    def __init__(self):\n",
    "        self.dataset = 'SceneFlowPSM'\n",
    "        self.arch = 'SpixelNet1l_bn'\n",
    "        # self.data= './data_preprocessing/Data'; self.data= './NYU'\n",
    "        self.data = \"./dataset/Monkaa\"\n",
    "        self.savepath = './checkpoints'\n",
    "        # self.train_img_height = 256; self.train_img_width= 512 \n",
    "        self.train_img_height = 128; self.train_img_width= 256\n",
    "        self.input_img_height = self.train_img_height\n",
    "        self.input_img_width = self.train_img_width\n",
    "        \n",
    "        self.workers = 4; self.epochs = 10  *10000\n",
    "        self.start_epoch = 0; self.epoch_size = 6000; self.batch_size = 1;\n",
    "        self.solver = 'adam'; self.lr= 0.0005; # 0.000005 \n",
    "        self.momentum = 0.9; self.beta = 0.999; self.weight_decay=4e-4;self.bias_decay=0\n",
    "        self.milestones=[200000]; self.additional_step=100000; \n",
    "        self.pos_weight = 0.003; self.downsize = 16;\n",
    "        self.gpu = '0'; self.print_freq = 10; self.record_freq  = 5; self.label_factor=5; self.pretrained = \"./checkpoints/SceneFlowPSM/SpixelNet1l_bn_adam_100000epochs_epochSize6000_b8_lr0.0005_posW0.003_/sfcn/model_best.tar\";\n",
    "        self.no_date=True\n",
    "        self.maxdisp = 192; self.psmmodel = 'basic'\n",
    "        self.seed = 1; self.pretrainedpsmnet = \"./checkpoints/SceneFlowPSM/SpixelNet1l_bn_adam_100000epochs_epochSize6000_b8_lr0.0005_posW0.003_/psm/model_best.tar\"\n",
    "\n",
    "args = ARG()\n",
    "\n",
    "# !----- NOTE the current code does not support cpu training -----!\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = args.gpu\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    print('Current code does not support CPU training! Sorry about that.')\n",
    "    exit(1)\n",
    "\n",
    "N_CLASSES = 50\n",
    "def foldercheck(save_path):\n",
    "    if not os.path.exists(save_path):\n",
    "        os.makedirs(save_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total classes 47.\n",
      "Number of eating_camera2_x2 samples : 151\n"
     ]
    }
   ],
   "source": [
    "# ==========  Data loading code ==============\n",
    "input_transform = transforms.Compose([\n",
    "    flow_transforms.ArrayToTensor(),\n",
    "    transforms.Normalize(mean=[0,0,0], std=[255,255,255]),\n",
    "    transforms.Normalize(mean=[0.411,0.432,0.45], std=[1,1,1])\n",
    "])\n",
    "\n",
    "val_input_transform = transforms.Compose([\n",
    "    flow_transforms.ArrayToTensor(),\n",
    "    transforms.Normalize(mean=[0, 0, 0], std=[255, 255, 255]),\n",
    "    transforms.Normalize(mean=[0.411, 0.432, 0.45], std=[1, 1, 1])\n",
    "])\n",
    "\n",
    "target_transform = transforms.Compose([\n",
    "    flow_transforms.ArrayToTensor(),\n",
    "])\n",
    "\n",
    "import numbers\n",
    "\n",
    "\n",
    "co_transform = flow_transforms.Compose([\n",
    "        flow_transforms.Resize((args.train_img_height ,args.train_img_width))\n",
    "    ])\n",
    "\n",
    "\n",
    "dataset = SceneFlowLoader(args.data, mode='eating_camera2_x2', transform=input_transform, target_transform=target_transform, co_transform=co_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = torch.utils.data.DataLoader(\n",
    "    dataset, batch_size=args.batch_size,\n",
    "    num_workers=args.workers, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> using pre-trained model 'SpixelNet1l_bn'\n",
      "was trained until 53 epochs\n",
      "Load pretrained model\n",
      "Number of PSM model parameters: 3287360\n"
     ]
    }
   ],
   "source": [
    "# ============== Load S-FCN model ====================\n",
    "if args.pretrained:\n",
    "    network_data = torch.load(args.pretrained)\n",
    "    args.arch = network_data['arch']\n",
    "    print(\"=> using pre-trained model '{}'\".format(args.arch))\n",
    "    print(f\"was trained until {network_data['epoch']} epochs\")\n",
    "else:\n",
    "    network_data = None\n",
    "    print(\"=> creating model '{}'\".format(args.arch))\n",
    "\n",
    "model = SpixelNet1l_bn( data = network_data).cuda()\n",
    "model = torch.nn.DataParallel(model).cuda()\n",
    "\n",
    "\n",
    "# ============== Load PSMNet model ====================\n",
    "if args.psmmodel == 'stackhourglass':\n",
    "    psmnet = stackhourglass(args.maxdisp, slicmode=False)\n",
    "elif args.psmmodel == 'basic':\n",
    "    psmnet = basic(args.maxdisp)\n",
    "else:\n",
    "    print('no model')\n",
    "psmnet = psmnet.to(device)\n",
    "\n",
    "if args.pretrainedpsmnet is not None:\n",
    "    print('Load pretrained model')\n",
    "    pretrain_dict = torch.load(args.pretrainedpsmnet)\n",
    "    psmnet.load_state_dict(pretrain_dict['state_dict'])\n",
    "\n",
    "psmnet = torch.nn.DataParallel(psmnet)\n",
    "print('Number of PSM model parameters: {}'.format(sum([p.data.nelement() for p in psmnet.parameters()])))\n",
    "\n",
    "# XY_feat: the coordinate feature for position loss term\n",
    "spixelID, XY_feat_stack = init_spixel_grid(args)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeOutput(cost, Ql, S):\n",
    "    upsampled_cost = upfeat(cost, Ql, S, S)\n",
    "    assert upsampled_cost.size()[2] == Ql.size()[2]\n",
    "    assert upsampled_cost.size()[3] == Ql.size()[3]\n",
    "    upsampled_cost = F.upsample(upsampled_cost.unsqueeze(1), [args.maxdisp,Ql.size()[2],Ql.size()[3]], mode='trilinear').squeeze(1)\n",
    "    output = F.softmax(upsampled_cost)\n",
    "    output = disparityregression(args.maxdisp)(output)\n",
    "    return output\n",
    "foldercheck(f'{args.savepath}/disparity_outputs/')\n",
    "with torch.no_grad():\n",
    "    psmnet.eval(); model.eval()\n",
    "    for i, sample in tqdm(enumerate(data_loader)):\n",
    "        imL, imR, label, labelR, disp_true = to_device(sample, device)\n",
    "\n",
    "        # ========== complete data loading ================\n",
    "        label_1hot = label2one_hot_torch(label, C=N_CLASSES) # set C=50 as SSN does\n",
    "        LABXY_feat_tensor = build_LABXY_feat(label_1hot, XY_feat_stack)  # B* (50+2 )* H * W\n",
    "        label_1hotR = label2one_hot_torch(labelR, C=N_CLASSES) # set C=50 as SSN does\n",
    "        LABXY_feat_tensorR = build_LABXY_feat(label_1hotR, XY_feat_stack)  # B* (50+2 )* H * W\n",
    "\n",
    "        # ========== predict association map ============\n",
    "        Ql = model(imL)\n",
    "        Qr = model(imR)\n",
    "\n",
    "        # ========== compute disparity map ============\n",
    "        mask = disp_true < args.maxdisp\n",
    "        mask.detach_()\n",
    "        #----\n",
    "        S = 4; m = 0.003\n",
    "        pooled_imL = poolfeat(imL, Ql.clone(), S, S)\n",
    "        pooled_imR = poolfeat(imR, Qr.clone(), S, S)\n",
    "\n",
    "        if args.psmmodel == 'stackhourglass':\n",
    "            cost1, cost2, cost3 = psmnet(pooled_imL, pooled_imR)\n",
    "            # output1 = torch.squeeze(output1,1); output2 = torch.squeeze(output2,1); output3 = torch.squeeze(output3,1)\n",
    "            # psmloss = 0.5*F.smooth_l1_loss(output1[mask], disp_true[mask], size_average=True) + \\\n",
    "            #     0.7*F.smooth_l1_loss(output2[mask], disp_true[mask], size_average=True) + \\\n",
    "            #         F.smooth_l1_loss(output3[mask], disp_true[mask], size_average=True) \n",
    "        elif args.psmmodel == 'basic':\n",
    "            cost = psmnet(pooled_imL,pooled_imR)\n",
    "            output  = computeOutput(cost, Ql, S)\n",
    "            # output = torch.squeeze(output,1)\n",
    "            psmloss = F.smooth_l1_loss(output[mask], disp_true[mask], size_average=True)\n",
    "\n",
    "        # ========== Visualization ============\n",
    "        mean_values = torch.tensor([0.411, 0.432, 0.45], dtype=imL.dtype).view(3, 1, 1)\n",
    "        input_l_save = (make_grid((imL.detach().cpu() + mean_values).clamp(0, 1), nrow=args.batch_size))\n",
    "        label_save = make_grid(args.label_factor * label)\n",
    "        curr_spixl_map = update_spixl_map(spixelID,Ql)\n",
    "        spixel_lab_save = make_grid(curr_spixl_map, nrow=args.batch_size)[0, :, :]\n",
    "        spixel_viz, _ = get_spixel_image(input_l_save, spixel_lab_save)\n",
    "\n",
    "        \n",
    "        mask = disp_true < 192\n",
    "        mask = imgtensor2np(mask[0]).squeeze().astype(np.uint8)\n",
    "\n",
    "        pred_disp = (imgtensor2np(output[0])[..., 0]).astype(np.uint8)\n",
    "        disparity = (imgtensor2np(disp_true[0])[..., 0]).astype(np.uint8)\n",
    "        leftim = (imgtensor2np(input_l_save)* 256).astype(np.uint8)\n",
    "\n",
    "        pred_disp *= mask\n",
    "        disparity *= mask\n",
    "\n",
    "\n",
    "        f, plts = plt.subplots(1,3, figsize=(10,5), dpi=300)\n",
    "        f.tight_layout()\n",
    "\n",
    "        # To remove the huge white borders\n",
    "\n",
    "        canvas = FigureCanvasAgg(f)\n",
    "        plts[0].imshow(leftim)\n",
    "        plts[0].set_title('Image')\n",
    "        plts[0].axis(\"off\")  ; plts[0].axis(\"tight\") ; plts[0].axis(\"image\")\n",
    "\n",
    "\n",
    "        plts[1].imshow(pred_disp)\n",
    "        plts[1].set_title('Predicted Disparities')\n",
    "        plts[1].axis(\"off\")  ; plts[1].axis(\"tight\") ; plts[1].axis(\"image\")\n",
    "\n",
    "\n",
    "        plts[2].imshow(disparity)\n",
    "        plts[2].set_title('Groundtruth Disparities')\n",
    "        plts[2].axis(\"off\")  ; plts[2].axis(\"tight\") ; plts[2].axis(\"image\")\n",
    "\n",
    "        canvas.draw()\n",
    "        s, (width, height) = canvas.print_to_buffer()\n",
    "        # Option 2a: Convert to a NumPy array.\n",
    "        X = np.fromstring(s, np.uint8).reshape((height, width, 4))\n",
    "        output = X[..., :3][450:950, 100:-50]\n",
    "\n",
    "        cv2.imwrite(f'{args.savepath}/disparity_outputs/{str(i).zfill(5)}.png', output)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "151\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "151it [00:37,  4.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done stitching\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "files=sorted(glob(f'{args.savepath}/disparity_outputs/*png'))\n",
    "print(len(files))\n",
    "for i, file in tqdm(enumerate(files)):\n",
    "    img = cv2.imread(file)\n",
    "    if(i==0):\n",
    "        foldercheck(f'{args.savepath}/disparity_video')\n",
    "        h,w = img.shape[:2]    \n",
    "        writer = cv2.VideoWriter(f'{args.savepath}/disparity_video/output1.mp4', cv2.VideoWriter_fourcc('m', 'p', '4', 'v'), 10, (w, h))\n",
    "    # out=cv2.cvtColor(out, cv2.COLOR_RGB2BGR)\n",
    "    writer.write(img)\n",
    "writer.release()\n",
    "print(\"Done stitching\")\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.6.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
